{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, this should convert my lovely dialogue txt file into the four enc/dec files needed to train the gbot on my own data.  xD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "''' \n",
    "    1. Read from 'movie-lines.txt'\n",
    "    2. Create a dictionary with ( key = line_id, value = text )\n",
    "'''\n",
    "def get_id2line():\n",
    "    lines=open('movie_lines.txt').read().split('\\n')\n",
    "    id2line = {}\n",
    "    for line in lines:\n",
    "        _line = line.split(' +++$+++ ')\n",
    "        if len(_line) == 5:\n",
    "            id2line[_line[0]] = _line[4]\n",
    "    return id2line\n",
    "\n",
    "'''\n",
    "    1. Read from 'movie_conversations.txt'\n",
    "    2. Create a list of [list of line_id's]\n",
    "'''\n",
    "def get_conversations():\n",
    "    conv_lines = open('movie_conversations.txt').read().split('\\n')\n",
    "    convs = [ ]\n",
    "    for line in conv_lines[:-1]:\n",
    "        _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "        convs.append(_line.split(','))\n",
    "    return convs\n",
    "\n",
    "'''\n",
    "    1. Get each conversation\n",
    "    2. Get each line from conversation\n",
    "    3. Save each conversation to file\n",
    "'''\n",
    "def extract_conversations(convs,id2line,path=''):\n",
    "    idx = 0\n",
    "    for conv in convs:\n",
    "        f_conv = open(path + str(idx)+'.txt', 'w')\n",
    "        for line_id in conv:\n",
    "            f_conv.write(id2line[line_id])\n",
    "            f_conv.write('\\n')\n",
    "        f_conv.close()\n",
    "        idx += 1\n",
    "\n",
    "'''\n",
    "    Get lists of all conversations as Questions and Answers\n",
    "    1. [questions]\n",
    "    2. [answers]\n",
    "'''\n",
    "def gather_dataset(convs, id2line):\n",
    "    questions = []; answers = []\n",
    "\n",
    "    for conv in convs:\n",
    "        if len(conv) %2 != 0:\n",
    "            conv = conv[:-1]\n",
    "        for i in range(len(conv)):\n",
    "            if i%2 == 0:\n",
    "                questions.append(id2line[conv[i]])\n",
    "            else:\n",
    "                answers.append(id2line[conv[i]])\n",
    "\n",
    "    return questions, answers\n",
    "\n",
    "\n",
    "'''\n",
    "    We need 4 files\n",
    "    1. train.enc : Encoder input for training\n",
    "    2. train.dec : Decoder input for training\n",
    "    3. test.enc  : Encoder input for testing\n",
    "    4. test.dec  : Decoder input for testing\n",
    "'''\n",
    "def prepare_seq2seq_files(questions, answers, path='',TESTSET_SIZE = 30000):\n",
    "    \n",
    "    # open files\n",
    "    train_enc = open(path + 'train.enc','w')\n",
    "    train_dec = open(path + 'train.dec','w')\n",
    "    test_enc  = open(path + 'test.enc', 'w')\n",
    "    test_dec  = open(path + 'test.dec', 'w')\n",
    "\n",
    "    # choose 30,000 (TESTSET_SIZE) items to put into testset\n",
    "    test_ids = random.sample([i for i in range(len(questions))],TESTSET_SIZE)\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        if i in test_ids:\n",
    "            test_enc.write(questions[i]+'\\n')\n",
    "            test_dec.write(answers[i]+ '\\n' )\n",
    "        else:\n",
    "            train_enc.write(questions[i]+'\\n')\n",
    "            train_dec.write(answers[i]+ '\\n' )\n",
    "        if i%10000 == 0:\n",
    "            print('\\n>> written %d lines' %(i))\n",
    "\n",
    "    # close files\n",
    "    train_enc.close()\n",
    "    train_dec.close()\n",
    "    test_enc.close()\n",
    "    test_dec.close()\n",
    "            \n",
    "\n",
    "####\n",
    "# main()\n",
    "####\n",
    "\n",
    "id2line = get_id2line()\n",
    "print('>> gathered id2line dictionary.\\n')\n",
    "convs = get_conversations()\n",
    "print('>> gathered conversations.\\n')\n",
    "questions, answers = gather_dataset(convs,id2line)\n",
    "print(questions[:2])\n",
    "print('>> gathered questions and answers.\\n')\n",
    "prepare_seq2seq_files(questions,answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
